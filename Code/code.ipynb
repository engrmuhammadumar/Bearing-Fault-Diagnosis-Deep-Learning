{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86431b9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: ['ball', 'healthy', 'inner', 'outer']\n",
      "Total samples: 1920\n",
      "Train samples: 1536, Val samples: 384\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 199\u001b[39m\n\u001b[32m    196\u001b[39m best_model_path = os.path.join(cfg.output_dir, \u001b[33m\"\u001b[39m\u001b[33mbest_cnn_resnet18.pth\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    198\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m1\u001b[39m, cfg.num_epochs + \u001b[32m1\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m199\u001b[39m     train_loss, train_acc = \u001b[43mtrain_one_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    200\u001b[39m     val_loss, val_acc     = evaluate(model, val_loader, criterion, cfg.device)\n\u001b[32m    202\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mEpoch [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcfg.num_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m] \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    203\u001b[39m           \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTrain Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m | Train Acc: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_acc*\u001b[32m100\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m% \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    204\u001b[39m           \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m|| Val Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m | Val Acc: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_acc*\u001b[32m100\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m%\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 151\u001b[39m, in \u001b[36mtrain_one_epoch\u001b[39m\u001b[34m(model, loader, optimizer, criterion, device)\u001b[39m\n\u001b[32m    148\u001b[39m model.train()\n\u001b[32m    149\u001b[39m running_loss, running_corrects, total = \u001b[32m0.0\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m0\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m151\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mloader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    152\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    153\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\torch\\utils\\data\\dataloader.py:494\u001b[39m, in \u001b[36mDataLoader.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    492\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._iterator\n\u001b[32m    493\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m494\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\torch\\utils\\data\\dataloader.py:427\u001b[39m, in \u001b[36mDataLoader._get_iterator\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    425\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    426\u001b[39m     \u001b[38;5;28mself\u001b[39m.check_worker_number_rationality()\n\u001b[32m--> \u001b[39m\u001b[32m427\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_MultiProcessingDataLoaderIter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\torch\\utils\\data\\dataloader.py:1172\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter.__init__\u001b[39m\u001b[34m(self, loader)\u001b[39m\n\u001b[32m   1165\u001b[39m w.daemon = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m   1166\u001b[39m \u001b[38;5;66;03m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[32m   1167\u001b[39m \u001b[38;5;66;03m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[32m   1168\u001b[39m \u001b[38;5;66;03m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[32m   1169\u001b[39m \u001b[38;5;66;03m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[32m   1170\u001b[39m \u001b[38;5;66;03m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[32m   1171\u001b[39m \u001b[38;5;66;03m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1172\u001b[39m \u001b[43mw\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1173\u001b[39m \u001b[38;5;28mself\u001b[39m._index_queues.append(index_queue)\n\u001b[32m   1174\u001b[39m \u001b[38;5;28mself\u001b[39m._workers.append(w)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Program Files\\Python313\\Lib\\multiprocessing\\process.py:121\u001b[39m, in \u001b[36mBaseProcess.start\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _current_process._config.get(\u001b[33m'\u001b[39m\u001b[33mdaemon\u001b[39m\u001b[33m'\u001b[39m), \\\n\u001b[32m    119\u001b[39m        \u001b[33m'\u001b[39m\u001b[33mdaemonic processes are not allowed to have children\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    120\u001b[39m _cleanup()\n\u001b[32m--> \u001b[39m\u001b[32m121\u001b[39m \u001b[38;5;28mself\u001b[39m._popen = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    122\u001b[39m \u001b[38;5;28mself\u001b[39m._sentinel = \u001b[38;5;28mself\u001b[39m._popen.sentinel\n\u001b[32m    123\u001b[39m \u001b[38;5;66;03m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[32m    124\u001b[39m \u001b[38;5;66;03m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Program Files\\Python313\\Lib\\multiprocessing\\context.py:224\u001b[39m, in \u001b[36mProcess._Popen\u001b[39m\u001b[34m(process_obj)\u001b[39m\n\u001b[32m    222\u001b[39m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[32m    223\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_Popen\u001b[39m(process_obj):\n\u001b[32m--> \u001b[39m\u001b[32m224\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_context\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mProcess\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Program Files\\Python313\\Lib\\multiprocessing\\context.py:337\u001b[39m, in \u001b[36mSpawnProcess._Popen\u001b[39m\u001b[34m(process_obj)\u001b[39m\n\u001b[32m    334\u001b[39m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[32m    335\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_Popen\u001b[39m(process_obj):\n\u001b[32m    336\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpopen_spawn_win32\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Popen\n\u001b[32m--> \u001b[39m\u001b[32m337\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Program Files\\Python313\\Lib\\multiprocessing\\popen_spawn_win32.py:97\u001b[39m, in \u001b[36mPopen.__init__\u001b[39m\u001b[34m(self, process_obj)\u001b[39m\n\u001b[32m     95\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     96\u001b[39m     reduction.dump(prep_data, to_child)\n\u001b[32m---> \u001b[39m\u001b[32m97\u001b[39m     \u001b[43mreduction\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mto_child\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     98\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     99\u001b[39m     set_spawning_popen(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Program Files\\Python313\\Lib\\multiprocessing\\reduction.py:60\u001b[39m, in \u001b[36mdump\u001b[39m\u001b[34m(obj, file, protocol)\u001b[39m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdump\u001b[39m(obj, file, protocol=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m     59\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m60\u001b[39m     \u001b[43mForkingPickler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision import datasets, transforms, models\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    classification_report,\n",
    "    roc_curve,\n",
    "    auc\n",
    ")\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# =========================================================\n",
    "# CONFIG\n",
    "# =========================================================\n",
    "class CFG:\n",
    "    data_root   = r\"F:\\NeuTech\\CWT\"                        # <-- single folder with class subfolders\n",
    "    output_dir  = r\"F:\\NeuTech\\new_results\\Comparison\\1\"\n",
    "    batch_size  = 32\n",
    "    num_workers = 4\n",
    "    num_epochs  = 2\n",
    "    lr          = 1e-4\n",
    "    seed        = 42\n",
    "    val_ratio   = 0.2                                      # 80% train / 20% val\n",
    "    device      = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "cfg = CFG()\n",
    "os.makedirs(cfg.output_dir, exist_ok=True)\n",
    "\n",
    "# =========================================================\n",
    "# SEED EVERYTHING\n",
    "# =========================================================\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(cfg.seed)\n",
    "\n",
    "# =========================================================\n",
    "# DATASETS & STRATIFIED TRAIN/VAL SPLIT\n",
    "# =========================================================\n",
    "# Base dataset without transform (for indexing, labels)\n",
    "base_dataset = datasets.ImageFolder(root=cfg.data_root)\n",
    "\n",
    "class_names = base_dataset.classes  # ['ball', 'healthy', 'inner', 'outer']\n",
    "num_classes = len(class_names)\n",
    "print(\"Classes:\", class_names)\n",
    "\n",
    "# Stratified split: per-class indices -> train/val\n",
    "label_to_indices = defaultdict(list)\n",
    "for idx, (_, label) in enumerate(base_dataset.samples):\n",
    "    label_to_indices[label].append(idx)\n",
    "\n",
    "train_indices = []\n",
    "val_indices   = []\n",
    "\n",
    "for label, idxs in label_to_indices.items():\n",
    "    idxs = np.array(idxs)\n",
    "    np.random.shuffle(idxs)\n",
    "    n_total = len(idxs)\n",
    "    n_val   = int(n_total * cfg.val_ratio)\n",
    "    # Ensure at least 1 val sample per class\n",
    "    n_val   = max(1, n_val)\n",
    "\n",
    "    val_idx   = idxs[:n_val]\n",
    "    train_idx = idxs[n_val:]\n",
    "\n",
    "    val_indices.extend(val_idx.tolist())\n",
    "    train_indices.extend(train_idx.tolist())\n",
    "\n",
    "# Shuffle final index lists\n",
    "np.random.shuffle(train_indices)\n",
    "np.random.shuffle(val_indices)\n",
    "\n",
    "print(f\"Total samples: {len(base_dataset)}\")\n",
    "print(f\"Train samples: {len(train_indices)}, Val samples: {len(val_indices)}\")\n",
    "\n",
    "# Transforms\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std =[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std =[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Two copies of ImageFolder with different transforms,\n",
    "# then restrict them by Subset with the same indices.\n",
    "train_dataset_full = datasets.ImageFolder(root=cfg.data_root, transform=train_transform)\n",
    "val_dataset_full   = datasets.ImageFolder(root=cfg.data_root, transform=val_transform)\n",
    "\n",
    "train_dataset = Subset(train_dataset_full, train_indices)\n",
    "val_dataset   = Subset(val_dataset_full,   val_indices)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, batch_size=cfg.batch_size,\n",
    "    shuffle=True, num_workers=cfg.num_workers, pin_memory=True\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, batch_size=cfg.batch_size,\n",
    "    shuffle=False, num_workers=cfg.num_workers, pin_memory=True\n",
    ")\n",
    "\n",
    "# =========================================================\n",
    "# MODEL: RESNET18 CNN\n",
    "# =========================================================\n",
    "def build_model(num_classes, pretrained=True):\n",
    "    model = models.resnet18(weights=models.ResNet18_Weights.DEFAULT if pretrained else None)\n",
    "    in_features = model.fc.in_features\n",
    "    model.fc = nn.Linear(in_features, num_classes)\n",
    "    return model\n",
    "\n",
    "model = build_model(num_classes=num_classes, pretrained=True)\n",
    "model = model.to(cfg.device)\n",
    "\n",
    "# =========================================================\n",
    "# TRAINING UTILITIES\n",
    "# =========================================================\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=cfg.lr)\n",
    "\n",
    "def train_one_epoch(model, loader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    running_loss, running_corrects, total = 0.0, 0, 0\n",
    "\n",
    "    for inputs, labels in loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        preds = outputs.argmax(dim=1)\n",
    "        running_loss    += loss.item() * inputs.size(0)\n",
    "        running_corrects += (preds == labels).sum().item()\n",
    "        total           += inputs.size(0)\n",
    "\n",
    "    epoch_loss = running_loss / total\n",
    "    epoch_acc  = running_corrects / total\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss, running_corrects, total = 0.0, 0, 0\n",
    "\n",
    "    for inputs, labels in loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss    = criterion(outputs, labels)\n",
    "        preds   = outputs.argmax(dim=1)\n",
    "\n",
    "        running_loss    += loss.item() * inputs.size(0)\n",
    "        running_corrects += (preds == labels).sum().item()\n",
    "        total           += inputs.size(0)\n",
    "\n",
    "    epoch_loss = running_loss / total\n",
    "    epoch_acc  = running_corrects / total\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "# =========================================================\n",
    "# TRAIN LOOP WITH BEST-MODEL SAVING\n",
    "# =========================================================\n",
    "best_val_acc   = 0.0\n",
    "best_model_path = os.path.join(cfg.output_dir, \"best_cnn_resnet18.pth\")\n",
    "\n",
    "for epoch in range(1, cfg.num_epochs + 1):\n",
    "    train_loss, train_acc = train_one_epoch(model, train_loader, optimizer, criterion, cfg.device)\n",
    "    val_loss, val_acc     = evaluate(model, val_loader, criterion, cfg.device)\n",
    "\n",
    "    print(f\"Epoch [{epoch}/{cfg.num_epochs}] \"\n",
    "          f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc*100:.2f}% \"\n",
    "          f\"|| Val Loss: {val_loss:.4f} | Val Acc: {val_acc*100:.2f}%\")\n",
    "\n",
    "    # Save best model\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(model.state_dict(), best_model_path)\n",
    "        print(f\"⭐ New best model saved with Val Acc: {best_val_acc*100:.2f}%\")\n",
    "\n",
    "print(f\"\\nBest Val Acc: {best_val_acc*100:.2f}%\")\n",
    "print(\"Best model path:\", best_model_path)\n",
    "\n",
    "# Load best before metrics/plots\n",
    "model.load_state_dict(torch.load(best_model_path, map_location=cfg.device))\n",
    "\n",
    "# =========================================================\n",
    "# HELPER: FORWARD TO LOGITS (GENERIC CNN)\n",
    "# =========================================================\n",
    "@torch.no_grad()\n",
    "def _forward_logits(model, x, device):\n",
    "    x = x.to(device)\n",
    "    logits = model(x)\n",
    "    return logits\n",
    "\n",
    "# =========================================================\n",
    "# 1) CONFUSION MATRIX\n",
    "# =========================================================\n",
    "@torch.no_grad()\n",
    "def plot_confusion_matrix(model, dataloader, class_names, device, save_path=\"confusion_matrix.png\"):\n",
    "    model.eval()\n",
    "    all_labels, all_preds = [], []\n",
    "\n",
    "    for batch in dataloader:\n",
    "        if isinstance(batch, dict):\n",
    "            x = batch[\"pixel_values\"]\n",
    "            y = batch[\"labels\"]\n",
    "        else:\n",
    "            x, y = batch\n",
    "\n",
    "        y = y.to(device)\n",
    "        logits = _forward_logits(model, x, device)\n",
    "        preds  = logits.argmax(dim=1)\n",
    "\n",
    "        all_labels.extend(y.cpu().numpy().tolist())\n",
    "        all_preds.extend(preds.cpu().numpy().tolist())\n",
    "\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(all_labels, all_preds, target_names=class_names))\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=class_names, yticklabels=class_names,\n",
    "                cbar=False, annot_kws={\"size\": 16, \"fontweight\": \"bold\"})\n",
    "    plt.xlabel('Predicted Label', fontsize=14, fontweight='bold')\n",
    "    plt.ylabel('True Label', fontsize=14, fontweight='bold')\n",
    "    plt.xticks(fontsize=12); plt.yticks(fontsize=12)\n",
    "    Path(save_path).parent.mkdir(parents=True, exist_ok=True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=600)\n",
    "    plt.show()\n",
    "    print(f\"✅ Confusion matrix saved at: {save_path}\")\n",
    "\n",
    "# =========================================================\n",
    "# 2) ROC CURVES (ONE-VS-REST)\n",
    "# =========================================================\n",
    "@torch.no_grad()\n",
    "def plot_roc_curves(model, dataloader, class_names, device, save_path=\"roc_curves.png\"):\n",
    "    model.eval()\n",
    "    num_classes = len(class_names)\n",
    "\n",
    "    all_labels, all_probs = [], []\n",
    "\n",
    "    for batch in dataloader:\n",
    "        if isinstance(batch, dict):\n",
    "            x = batch[\"pixel_values\"]\n",
    "            y = batch[\"labels\"]\n",
    "        else:\n",
    "            x, y = batch\n",
    "\n",
    "        logits = _forward_logits(model, x, device)\n",
    "        probs  = torch.softmax(logits, dim=1)\n",
    "\n",
    "        all_labels.extend(y.cpu().numpy().tolist())\n",
    "        all_probs.extend(probs.cpu().numpy().tolist())\n",
    "\n",
    "    all_labels = np.array(all_labels)\n",
    "    all_probs  = np.array(all_probs)\n",
    "    y_bin = label_binarize(all_labels, classes=list(range(num_classes)))  # [N, C]\n",
    "\n",
    "    fpr, tpr, roc_auc = {}, {}, {}\n",
    "    for i in range(num_classes):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_bin[:, i], all_probs[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    for i in range(num_classes):\n",
    "        plt.plot(fpr[i], tpr[i], lw=2, label=f'{class_names[i]} (AUC = {roc_auc[i]:.3f})')\n",
    "\n",
    "    # Chance line\n",
    "    plt.plot([0, 1], [0, 1], color='gray', lw=2, linestyle='--')\n",
    "\n",
    "    plt.xlabel('False Positive Rate', fontsize=14, fontweight='bold')\n",
    "    plt.ylabel('True Positive Rate', fontsize=14, fontweight='bold')\n",
    "    plt.legend(loc='lower right', fontsize=11)\n",
    "    plt.grid(alpha=0.3)\n",
    "    Path(save_path).parent.mkdir(parents=True, exist_ok=True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=600)\n",
    "    plt.show()\n",
    "    print(f\"✅ ROC curves saved at: {save_path}\")\n",
    "\n",
    "# =========================================================\n",
    "# 3) t-SNE FEATURE EXTRACTION (CNN)\n",
    "# =========================================================\n",
    "@torch.no_grad()\n",
    "def extract_features(model, dataloader, device):\n",
    "    \"\"\"\n",
    "    Extracts features from the CNN before the final FC layer\n",
    "    (global average pooled features for ResNet).\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    feature_extractor = nn.Sequential(*list(model.children())[:-1]).to(device)\n",
    "\n",
    "    all_features, all_labels = [], []\n",
    "\n",
    "    for batch in dataloader:\n",
    "        if isinstance(batch, dict):\n",
    "            x = batch[\"pixel_values\"]\n",
    "            y = batch[\"labels\"]\n",
    "        else:\n",
    "            x, y = batch\n",
    "\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        feats = feature_extractor(x)   # [B, C, 1, 1]\n",
    "        feats = feats.view(feats.size(0), -1)  # [B, C]\n",
    "        all_features.append(feats.cpu().numpy())\n",
    "        all_labels.append(y.cpu().numpy())\n",
    "\n",
    "    features = np.concatenate(all_features, axis=0)\n",
    "    labels   = np.concatenate(all_labels, axis=0)\n",
    "    return features, labels\n",
    "\n",
    "def compute_tsne(features, n_components=2, random_state=42):\n",
    "    tsne = TSNE(n_components=n_components, random_state=random_state,\n",
    "                init='pca', perplexity=30)\n",
    "    return tsne.fit_transform(features)\n",
    "\n",
    "def plot_tsne(features_tsne, labels, class_names, save_path=\"tsne_cnn_cwt.png\"):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "\n",
    "    colors  = ['blue', 'green', 'red', 'orange']\n",
    "    markers = ['o', 's', '^', 'D']\n",
    "\n",
    "    for i, (cls, color, marker) in enumerate(zip(class_names, colors, markers)):\n",
    "        mask = (labels == i)\n",
    "        plt.scatter(features_tsne[mask, 0], features_tsne[mask, 1],\n",
    "                    label=cls, color=color, marker=marker, alpha=0.7)\n",
    "\n",
    "    plt.legend(title=\"Classes\", fontsize=12, title_fontsize=13,\n",
    "               loc='best', frameon=True)\n",
    "    plt.xlabel('t-SNE Component 1', fontsize=14, fontweight='bold')\n",
    "    plt.ylabel('t-SNE Component 2', fontsize=14, fontweight='bold')\n",
    "    plt.xticks(fontsize=12, fontweight='bold')\n",
    "    plt.yticks(fontsize=12, fontweight='bold')\n",
    "\n",
    "    Path(save_path).parent.mkdir(parents=True, exist_ok=True)\n",
    "    plt.savefig(save_path, dpi=1000)\n",
    "    plt.show()\n",
    "    print(f\"✅ t-SNE plot saved at: {save_path}\")\n",
    "\n",
    "# =========================================================\n",
    "# RUN METRICS & PLOTS ON VALIDATION SET\n",
    "# =========================================================\n",
    "cm_path   = os.path.join(cfg.output_dir, \"cm_val.png\")\n",
    "roc_path  = os.path.join(cfg.output_dir, \"roc_val.png\")\n",
    "tsne_path = os.path.join(cfg.output_dir, \"tsne_features_cnn.png\")\n",
    "\n",
    "plot_confusion_matrix(model, val_loader, class_names, cfg.device, save_path=cm_path)\n",
    "plot_roc_curves(model, val_loader, class_names, cfg.device, save_path=roc_path)\n",
    "\n",
    "features, labels = extract_features(model, val_loader, cfg.device)\n",
    "features_2d = compute_tsne(features)\n",
    "plot_tsne(features_2d, labels, class_names, save_path=tsne_path)\n",
    "\n",
    "print(\"✅ All done.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8401c01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
